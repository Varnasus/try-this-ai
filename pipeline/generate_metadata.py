import json
import os
import re

from dotenv import load_dotenv
from openai import OpenAI

from config import Config, Environment

# Load configuration and environment variables
Config.load_config(Environment.PRODUCTION)
load_dotenv()

# Initialize OpenAI client with configured settings
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"), timeout=Config.get("api.openai.timeout", 30)
)


def is_short_form(script_text):
    max_words = Config.get("video.short_form.max_words", 120)
    return len(script_text.split()) < max_words


def generate_video_metadata(script_text):
    # Get configuration values
    channel_name = Config.get("youtube.channel_name", "Try This AI")
    max_title_length = Config.get("youtube.metadata.max_title_length", 100)
    max_description_length = Config.get("youtube.metadata.max_description_length", 5000)
    max_tags = Config.get("youtube.metadata.max_tags", 500)

    prompt = f"""
You're writing YouTube metadata for a short, punchy, faceless AI channel called \"{channel_name}\".

The tone should be:
- Bold and attention-grabbing
- Tailored for dev-curious viewers
- Written in plain English
- Avoid clickbait, but keep it edgy
- {max_title_length} characters or less for titles

This is for a { "YouTube Short" if is_short_form(script_text) else "full-length video" }.

Based on this script:
\"\"\"
{script_text}
\"\"\"

Return JSON:
{{
  "title": "string (max {max_title_length} characters)",
  "description": "1-2 sentence summary with a subtle CTA to try the tool or idea",
  "tags": ["tag1", "tag2", "..."] (max {max_tags} tags)
}}
"""

    try:
        response = client.chat.completions.create(
            model=Config.get("api.openai.model"),
            messages=[{"role": "user", "content": prompt}],
            temperature=Config.get("api.openai.temperature", 0.7),
            max_tokens=Config.get("api.openai.max_tokens", 2000),
        )

        raw = response.choices[0].message.content

        # Extract JSON object from GPT response, ignoring markdown code fencing
        json_match = re.search(r"\{.*\}", raw, re.DOTALL)
        if json_match:
            metadata = json.loads(json_match.group())

            # Validate and truncate metadata based on configuration
            if len(metadata["title"]) > max_title_length:
                metadata["title"] = metadata["title"][:max_title_length]

            if len(metadata["description"]) > max_description_length:
                metadata["description"] = metadata["description"][
                    :max_description_length
                ]

            if len(metadata["tags"]) > max_tags:
                metadata["tags"] = metadata["tags"][:max_tags]

            return metadata
        else:
            raise ValueError("No valid JSON found in GPT response")
    except Exception as e:
        print(f"Error generating metadata: {str(e)}")
        return {
            "title": "AI Video",
            "description": "Generated by Try This AI",
            "tags": ["ai", "video", "generation"],
        }


if __name__ == "__main__":
    print("üöÄ Running test...")

    test_script = """
This is a little-known AI API that can summarize any document instantly. I used it to summarize a 200-page research paper into 3 bullet points.

It's available for free and takes one line of Python to use. Try this AI tool to save hours.
"""

    try:
        metadata = generate_video_metadata(test_script)
        print("‚úÖ Metadata generated:")
        print(json.dumps(metadata, indent=2))
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
